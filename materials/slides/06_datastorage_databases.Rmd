---
title: "Big Data Analytics"
subtitle: 'Lecture 6:<br>Data Storage, Databases Interaction with R'
author: "Prof. Dr. Ulrich Matter"
date: "25/03/2019"
output:   
  ioslides_presentation:
    css: ../../style/ioslides.css
logo: ../img/logo.png
bibliography: ../references/bigdata.bib
---


```{r set-options, echo=FALSE, cache=FALSE, purl=FALSE}
options(width = 100)
library(knitr)
```


# Updates

## Group Examination of Part I

- 25 points max.
     - 15 points: Implementation of specific tasks.
     - 10 points: Own extension of the research report (1-2 pages).
- Final grade 50% (25 points) group examination task + 50% (25 points) oral exam (Part II).
- Release: This Friday, 17:00.

## Test registration of groups



## Schedule {.smaller}

 1. Introduction: Big Data, Data Economy (Concepts). M: Walkowiak (2016): Chapter 1
 2. Programming with Data, R Refresher Course (Concepts/Applied). M: Walkowiak (2016): Chapter 2
 3. Computation and Memory (Concepts)
 4. Cleaning and Transformation of Big Data (Applied). M: Walkowiak (2016): Chapter 3: p. 74‐118.
 5. Aggregation and Visualization (Applied: data tables, ggplot). M: Walkowiak (2016): Chapter 3: p. 118‐127. C: Wickham et al. (2015), Schwabish (2014).
 6. *Data Storage, Databases Interaction with R. M: Walkowiak (2016): Chapter 5.*
 7. Distributed Systems, MapReduce/Hadoop with R (Concepts/Applied). M: Walkowiak (2016): Chapter 4.
 


# Data Visualization Part II



```{r warning=FALSE, echo=FALSE, message=FALSE}

# SET UP----
# see 05_aggregtion_visualization.Rmd for details
# load packages
library(data.table)
library(ggplot2)

# import data into RAM (needs around 200MB)
taxi <- fread("../data/tlc_trips.csv",
              nrows = 1000000)



# first, we remove the empty vars V8 and V9
taxi$V8 <- NULL
taxi$V9 <- NULL


# set covariate names according to the data dictionary
# see https://www1.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_yellow.pdf
# note instead of taxizonne ids, long/lat are provided

varnames <- c("vendor_id",
              "pickup_time",
              "dropoff_time",
              "passenger_count",
              "trip_distance",
              "start_long",
              "start_lat",
              "dest_long",
              "dest_lat",
              "payment_type",
              "fare_amount",
              "extra",
              "mta_tax",
              "tip_amount",
              "tolls_amount",
              "total_amount")
names(taxi) <- varnames

# clean the factor levels
taxi$payment_type <- tolower(taxi$payment_type)
taxi$payment_type <- factor(taxi$payment_type, levels = unique(taxi$payment_type))     




```


## Visualization of spatial data with `ggplot2`

- Data source: NYC Taxi & Limousine Commission (TLC).
- Data on all trip records including *pick-up and drop-off times/locations*.


## Preparations

- Load packages for GIS data/operations

```{r message=FALSE, warning=FALSE}
# load GIS packages
library(rgdal)
library(rgeos)
```

## Download map data

```{r message=FALSE, warning=FALSE}
# download the zipped shapefile to a temporary file, unzip
URL <- "https://www1.nyc.gov/assets/planning/download/zip/data-maps/open-data/nycd_19a.zip"
tmp_file <- tempfile()
download.file(URL, tmp_file)
file_path <- unzip(tmp_file, exdir= "../data")
# delete the temporary file
unlink(tmp_file)

```

## Import map data

```{r message=FALSE, warning=FALSE}
# read GIS data
nyc_map <- readOGR(file_path[1], verbose = FALSE)

# have a look at the polygons that constitute the map
summary(nyc_map)
```


## Change map projection

```{r}
# transform the projection
nyc_map <- spTransform(nyc_map, 
                       CRS("+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0"))
# check result
summary(nyc_map)
```

## Prepare map for plotting with `ggplot2`

```{r warning=FALSE, message=FALSE}
nyc_map <- fortify(nyc_map)
```


## Prepare pick-up and drop-off data


```{r}
# taxi trips plot data
taxi_trips <- taxi[start_long <= max(nyc_map$long) & 
                        start_long >= min(nyc_map$long) &
                        dest_long <= max(nyc_map$long) &
                        dest_long >= min(nyc_map$long) &
                        start_lat <= max(nyc_map$lat) & 
                        start_lat >= min(nyc_map$lat) &
                        dest_lat <= max(nyc_map$lat) &
                        dest_lat >= min(nyc_map$lat) 
                        ]
taxi_trips <- taxi_trips[sample(nrow(taxi_trips), 50000)]

```


## Code time dimension(s)

```{r}
taxi_trips$start_time <- hour(taxi_trips$pickup_time)
```


```{r}
# define new variable for facets
taxi_trips$time_of_day <- "Morning"
taxi_trips[start_time > 12 & start_time < 17]$time_of_day <- "Afternoon"
taxi_trips[start_time %in% c(17:24, 0:5)]$time_of_day <- "Evening/Night"
taxi_trips$time_of_day  <- factor(taxi_trips$time_of_day, levels = c("Morning", "Afternoon", "Evening/Night"))

```


## Base plot: Map of NYC


```{r}
# set up the canvas
locations <- ggplot(taxi_trips, aes(x=long, y=lat))
# add the map geometry
locations <- locations + geom_map(data = nyc_map,
                                  map = nyc_map,
                                  aes(map_id = id))
locations
```

## Add pick-up locations

```{r}
# add pick-up locations to plot
locations + 
     geom_point(aes(x=start_long, y=start_lat),
                color="orange",
                size = 0.1,
                alpha = 0.2)

```

## Add drop-off locations

```{r}
# add pick-up locations to plot
locations +
     geom_point(aes(x=dest_long, y=dest_lat),
                color="steelblue",
                size = 0.1,
                alpha = 0.2) +
     geom_point(aes(x=start_long, y=start_lat),
                color="orange",
                size = 0.1,
                alpha = 0.2)
 

```


## Taxi traffic over the course of a day

```{r fig.height=3, fig.width=9}

# pick-up locations 
locations +
     geom_point(aes(x=start_long, y=start_lat),
                color="orange",
                size = 0.1,
                alpha = 0.2) +
     facet_wrap(vars(time_of_day))
 
```

## Taxi traffic over the course of a day

```{r fig.height=3, fig.width=9}

# drop-off locations 
locations +
     geom_point(aes(x=dest_long, y=dest_lat),
                color="steelblue",
                size = 0.1,
                alpha = 0.2) +
     facet_wrap(vars(time_of_day))
 
```


## Taxi traffic over the course of a day

```{r}
# drop-off locations 
locations +
     geom_point(aes(x=dest_long, y=dest_lat, color = start_time ),
                size = 0.1,
                alpha = 0.2) +
     scale_colour_gradient2( low = "red", mid = "yellow", high = "red",
                             midpoint = 12)
 
```





# Data Storage and Databases


## (Big) Data Storage

 - $(I)$ How can we store large data sets permanently on a mass storage device in an efficient way (here, efficient can be understood as 'not taking up too much space')?
 - $(II)$ How can we load (parts of) this data set in an efficient way (here, efficient~fast) for analysis?

## We look at this problem in two situations: 

 - The data need to be stored locally (e.g., on the hard disk of our laptop).
 - The data can be stored on a server 'in the cloud' (next lecture).

## Many new database types for Big Data

```{r whatis, echo=FALSE, out.width = "80%", fig.align='center', purl=FALSE, fig.cap="NoSQL/NewSQL systems. Source: https://img.deusm.com/informationweek/2014/06/1269559/NoSQL-&-NewSQL.jpg"}
include_graphics("https://img.deusm.com/informationweek/2014/06/1269559/NoSQL-&-NewSQL.jpg")
```




## Simple distinction

- *SQL/Relational Database Systems (RDBMS)*: Relational data model, tabular relations.
     - In use for a long time, very mature, very accurate/stable.
- *NoSQL ('non-SQL', sometimes 'Not only SQL')*: Different data models, column, document, key-value, graph.
     - Horizontal scaling.
     - Non-tabular data.
     - Typically used to handle very large amounts of data.


## RDBMS basics

- *Relational data model*
     - Data split into several tables (avoid redundancies).
     - Tables are linked via key-variables/columns.
     - Save storage space.
- *Indexing*
     - Table columns (particularly keys) are indexed.
     - Reduces number of disk accesses required to query data.
     - Makes querying/loading of data more efficient/faster.




## Getting started with (R)SQLite

- [SQLite](https://sqlite.org/index.html)
     - Free, full-featured SQL database engine.
     - Widely used across platforms.
     - Typically pre-installed on Windows/MacOSX.
- [RSQLite](https://cran.r-project.org/web/packages/RSQLite/index.html)
     - Embeds SQLite in R.
     - Use SQLite from within an R session.


## Exercise 1:  First steps in SQLite (Terminal)

- Set up a new database called `mydb.sqlite`.

```{bash eval=FALSE}
cd materials/data 
```

```{bash eval= FALSE}
sqlite3 mydb.sqlite
```

```{sql eval = FALSE}
.tables
```


## Import data from CSV files

```{r echo=FALSE, message=FALSE}
library(DBI)
con <- dbConnect(RSQLite::SQLite(), "../data/mydb.sqlite")
```


```{sql connection=con, eval = FALSE}
CREATE TABLE econ(
"date" DATE,
"pce" REAL,
"pop" INTEGER,
"psavert" REAL,
"uempmed" REAL,
"unemploy" INTEGER
);

.mode csv
.import economics.csv econ
```


## Inspect the database


```{}
.tables
```

```{}
# econ
```

```{}
.schema econ
```

```{}
# CREATE TABLE econ(
# "date" DATE,
# "pce" REAL,
# "pop" INTEGER,
# "psavert" REAL,
# "uempmed" REAL,
# "unemploy" INTEGER
# );
```

## Set options for output

```{sql connection=con, eval = FALSE}
.header on
```

```{sql connection=con, eval = FALSE}
.mode columns
```



## Issue queries: Example 1

In our first query, we select all (`*`) variable values of the observation of January 1968.

```{sql connection=con}
select * from econ where date = '1968-01-01'
```

## Issue queries: Example 2

Now let's select all year/months in which there were more than 15 million unemployed, ordered by date.

```{sql connection=con}
select date from econ 
where unemploy > 15000
order by date;
```

## Close SQLite

When done working with the database, we can exit SQLite with the `.quit` command.




## Exercise 2: Indices and joins

 - Import several related tables.
 - Add indices to tables. 

## Initiate DB, import data

We set up a new database called `air.sqlite` and import the csv-file `flights.csv` (used in previous lectures) as a first table.

```{bash echo=TRUE, eval=FALSE}
# create database and run sqlite
sqlite3 air.sqlite

```

## Import data from CSVs


```{sql connection=con, eval = FALSE}
.mode csv
.import flights.csv flights
```


```{r echo=FALSE, message=FALSE}
library(DBI)
# set up a connection for the examples
con_air <- dbConnect(RSQLite::SQLite(), "../data/air_final.sqlite")
```


## Inspect the `flights` table

Again, we can check if everything worked out well with `.tables` and `.schema`.


```{sql connection=con_air, eval = FALSE}
.tables
.schema flights
```

## Related tables 

- [`airports.csv`](http://stat-computing.org/dataexpo/2009/airports.csv): Describes the locations of US Airports (relates to `origin` and `dest`).
- [`carriers.csv`](http://stat-computing.org/dataexpo/2009/carriers.csv): A listing of carrier codes with full names (relates to the `carrier`-column in `flights`.


```{r echo=FALSE, eval=FALSE}
# ASA source
URL_AIRPORTS <- "http://stat-computing.org/dataexpo/2009/airports.csv"
URL_CARRIERS <- "http://stat-computing.org/dataexpo/2009/carriers.csv"

# download
download.file(URL_AIRPORTS, destfile = "../data/airports.csv", quiet = TRUE)
download.file(URL_CARRIERS, destfile = "../data/carriers.csv", quiet = TRUE)

# re-format (facilitates import)
fwrite(fread("../data/airports.csv"), "../data/airports.csv")
fwrite(fread("../data/carriers.csv"), "../data/carriers.csv")

```


## Import related tables

Import from csv-file
```{sql connection=con_air, eval = FALSE}
.mode csv
.import airports.csv airports
.import carriers.csv carriers
```

Inspect the result
```{sql connection=con_air, eval = FALSE}
.tables
.schema airports
.schema carriers
```

## Issue queries with joins

 - Goal: A table containing flights data for all `United Air Lines Inc.`-flights departing from `Newark Intl` airport, ordered by flight number. 
 - For the sake of the exercise, we only show the first 10 results of this query (`LIMIT 10`).


## Issue queries with joins

```{sql connection=con_air, eval = TRUE}
SELECT 
year,
month, 
day,
dep_delay,
flight
FROM (flights INNER JOIN airports ON flights.origin=airports.iata) 
INNER JOIN carriers ON flights.carrier = carriers.Code
WHERE carriers.Description = 'United Air Lines Inc.'
AND airports.airport = 'Newark Intl'
ORDER BY flight
LIMIT 10;

```

## Add indices

```{sql connection=con_air, eval = FALSE}
CREATE INDEX iata_airports ON airports (iata);
CREATE INDEX origin_flights ON flights (origin);
CREATE INDEX carrier_flights ON flights (carrier);
CREATE INDEX code_carriers ON carriers (code);

```


## Re-run the query (with indices)

```{sql connection=con_air, eval = TRUE}
SELECT 
year,
month, 
day,
dep_delay,
flight
FROM (flights INNER JOIN airports ON flights.origin=airports.iata) 
INNER JOIN carriers ON flights.carrier = carriers.Code
WHERE carriers.Description = 'United Air Lines Inc.'
AND airports.airport = 'Newark Intl'
ORDER BY flight
LIMIT 10;

```



## SQLite from within R

- Use `RSQLite` to set up and query `air.sqlite` as shown above.
- All done from within an R session.


## Creating a new database with `RSQLite`

```{r}
# load packages
library(RSQLite)

# initiate the database
con_air <- dbConnect(SQLite(), "../data/air.sqlite")
```

## Importing data


```{r}

# import data into current R sesssion
flights <- fread("../data/flights.csv")
airports <- fread("../data/airports.csv")
carriers <- fread("../data/carriers.csv")

# add tables to database
dbWriteTable(con_air, "flights", flights)
dbWriteTable(con_air, "airports", airports)
dbWriteTable(con_air, "carriers", carriers)

```

## Issue queries with `RSQLite`

```{r}
# define query
delay_query <-
"SELECT 
year,
month, 
day,
dep_delay,
flight
FROM (flights INNER JOIN airports ON flights.origin=airports.iata) 
INNER JOIN carriers ON flights.carrier = carriers.Code
WHERE carriers.Description = 'United Air Lines Inc.'
AND airports.airport = 'Newark Intl'
ORDER BY flight
LIMIT 10;
"
```

## Issue queries with `RSQLite`

```{r}
# issue query
delays_df <- dbGetQuery(con_air, delay_query)
delays_df
```

## Close the connection to SQLite

```{r}
dbDisconnect(con_air)
```





```{r echo=FALSE}
# clean up
unlink("../data/air.sqlite")
```



## References {.smaller}

<style>
slides > slide { overflow: scroll; }
slides > slide:not(.nobackground):after {
  content: '';
}
</style>


